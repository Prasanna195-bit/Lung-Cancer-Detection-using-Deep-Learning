{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUNG CANCER DETECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import*\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING VARIABLES AND ASSIGNING PATH\n",
    "train_path='New_Segment/train'\n",
    "valid_path='New_Segment/valid'\n",
    "test_path='New_Segment/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1082 images belonging to 2 classes.\n",
      "Found 197 images belonging to 2 classes.\n",
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches=ImageDataGenerator().flow_from_directory(train_path,target_size=(224,224),classes=['binary'],batch_size=10)\n",
    "valid_batches=ImageDataGenerator().flow_from_directory(valid_path,target_size=(224,224),classes=['binary'],batch_size=5)\n",
    "test_batches=ImageDataGenerator().flow_from_directory(test_path,target_size=(224,224),classes=['binary'],batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_callback = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(2, activation='softmax')(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 27,561,282\n",
      "Trainable params: 12,846,594\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(lr=.0001),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 108 steps, validate for 39 steps\n",
      "Epoch 1/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.5513 - accuracy: 0.7458\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83077, saving model to VGG_16_weights.best.hdf5\n",
      "108/108 [==============================] - 20s 187ms/step - loss: 2.5502 - accuracy: 0.7453 - val_loss: 1.6462 - val_accuracy: 0.8308\n",
      "Epoch 2/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.2649 - accuracy: 0.8644\n",
      "Epoch 00002: val_accuracy did not improve from 0.83077\n",
      "108/108 [==============================] - 17s 155ms/step - loss: 1.2550 - accuracy: 0.8647 - val_loss: 1.8585 - val_accuracy: 0.8154\n",
      "Epoch 3/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.7363 - accuracy: 0.9171\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.83077\n",
      "108/108 [==============================] - 17s 156ms/step - loss: 0.7409 - accuracy: 0.9170 - val_loss: 2.4765 - val_accuracy: 0.8154\n",
      "Epoch 4/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.9576\n",
      "Epoch 00004: val_accuracy improved from 0.83077 to 0.84103, saving model to VGG_16_weights.best.hdf5\n",
      "108/108 [==============================] - 18s 166ms/step - loss: 0.2751 - accuracy: 0.9571 - val_loss: 1.8971 - val_accuracy: 0.8410\n",
      "Epoch 5/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1910 - accuracy: 0.9633\n",
      "Epoch 00005: val_accuracy improved from 0.84103 to 0.85128, saving model to VGG_16_weights.best.hdf5\n",
      "108/108 [==============================] - 18s 165ms/step - loss: 0.1892 - accuracy: 0.9636 - val_loss: 1.7009 - val_accuracy: 0.8513\n",
      "Epoch 6/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9718\n",
      "Epoch 00006: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 157ms/step - loss: 0.1441 - accuracy: 0.9720 - val_loss: 1.8219 - val_accuracy: 0.8359\n",
      "Epoch 7/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9765\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 157ms/step - loss: 0.1532 - accuracy: 0.9767 - val_loss: 1.8883 - val_accuracy: 0.8308\n",
      "Epoch 8/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9831\n",
      "Epoch 00008: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 157ms/step - loss: 0.1045 - accuracy: 0.9832 - val_loss: 1.9024 - val_accuracy: 0.8359\n",
      "Epoch 9/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.9821\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 157ms/step - loss: 0.0750 - accuracy: 0.9823 - val_loss: 1.8822 - val_accuracy: 0.8359\n",
      "Epoch 10/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 0.9708\n",
      "Epoch 00010: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 157ms/step - loss: 0.1253 - accuracy: 0.9711 - val_loss: 1.8893 - val_accuracy: 0.8359\n",
      "Epoch 11/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9849\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 157ms/step - loss: 0.0545 - accuracy: 0.9851 - val_loss: 1.8884 - val_accuracy: 0.8359\n",
      "Epoch 12/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0816 - accuracy: 0.9783\n",
      "Epoch 00012: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.0809 - accuracy: 0.9785 - val_loss: 1.8883 - val_accuracy: 0.8359\n",
      "Epoch 13/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9812\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.0720 - accuracy: 0.9813 - val_loss: 1.8919 - val_accuracy: 0.8359\n",
      "Epoch 14/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9793\n",
      "Epoch 00014: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.0943 - accuracy: 0.9795 - val_loss: 1.8930 - val_accuracy: 0.8359\n",
      "Epoch 15/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9821\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.0621 - accuracy: 0.9823 - val_loss: 1.8938 - val_accuracy: 0.8359\n",
      "Epoch 16/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0848 - accuracy: 0.9783\n",
      "Epoch 00016: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.0855 - accuracy: 0.9776 - val_loss: 1.8940 - val_accuracy: 0.8359\n",
      "Epoch 17/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9718\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.1293 - accuracy: 0.9720 - val_loss: 1.8940 - val_accuracy: 0.8359\n",
      "Epoch 18/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9727\n",
      "Epoch 00018: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.1164 - accuracy: 0.9729 - val_loss: 1.8941 - val_accuracy: 0.8359\n",
      "Epoch 19/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.9736\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.55999976772614e-10.\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.1312 - accuracy: 0.9729 - val_loss: 1.8940 - val_accuracy: 0.8359\n",
      "Epoch 20/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9736\n",
      "Epoch 00020: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.1008 - accuracy: 0.9739 - val_loss: 1.8940 - val_accuracy: 0.8359\n",
      "Epoch 21/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0786 - accuracy: 0.9831\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 5.119999424429978e-11.\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.0780 - accuracy: 0.9832 - val_loss: 1.8940 - val_accuracy: 0.8359\n",
      "Epoch 22/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9755\n",
      "Epoch 00022: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.1012 - accuracy: 0.9748 - val_loss: 1.8940 - val_accuracy: 0.8359\n",
      "Epoch 23/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9746\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0239999126415712e-11.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 159ms/step - loss: 0.1114 - accuracy: 0.9739 - val_loss: 1.8940 - val_accuracy: 0.8359\n",
      "Epoch 24/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0598 - accuracy: 0.9793\n",
      "Epoch 00024: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 159ms/step - loss: 0.0592 - accuracy: 0.9795 - val_loss: 1.8940 - val_accuracy: 0.8359\n",
      "Epoch 25/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0923 - accuracy: 0.9783\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.0479997905886727e-12.\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85128\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.0915 - accuracy: 0.9785 - val_loss: 1.8940 - val_accuracy: 0.8359\n"
     ]
    }
   ],
   "source": [
    "learn_control = ReduceLROnPlateau(monitor='val_accuracy', patience=5,\n",
    "                                  verbose=1,factor=0.2)\n",
    "\n",
    "filepath=\"VGG_16_weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history= model.fit_generator(train_batches, steps_per_epoch=108,\n",
    "                              validation_data=valid_batches,validation_steps=39,epochs=25,verbose=1,\n",
    "                              callbacks=[learn_control, checkpoint,time_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TimeHistory at 0x1e23a7148c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_callback"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
